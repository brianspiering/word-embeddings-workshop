{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have word vectors, what can we do?\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Math with words!\n",
    "\n",
    "<center><img src=\"http://rlv.zcache.com/math_is_awesome_poster-re24bd4726be24b82acc1d83fe7b4a8e4_cru_8byvr_512.jpg\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Types of Word Math\n",
    "----\n",
    "\n",
    "1. Distance\n",
    "2. Arithmetic\n",
    "3. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Distance\n",
    "----\n",
    "\n",
    "<center><img src=\"http://blog.krecan.net/wp-content/family.png\" width=\"600\"/></center>\n",
    "\n",
    "The relationships between words can encoded as distance through the space.\n",
    "\n",
    "Words that are related will be closer than unrelate words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ways to measure distance\n",
    "----\n",
    "<center><img src=\"http://i1.wp.com/dataaspirant.com/wp-content/uploads/2015/04/euclidean.png?w=600\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://i2.wp.com/dataaspirant.com/wp-content/uploads/2015/04/manhattan.png?w=600\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://i2.wp.com/dataaspirant.com/wp-content/uploads/2015/04/cosine.png?resize=610%2C468\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Read more here](http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "Which distance metric should we use for word vectors and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Cosine similarity is most often used in NLP.\n",
    "\n",
    "Because cosine similarity is automatically normalized, scaled between -1 and 1 (similar to a correlation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://upload.wikimedia.org/math/f/3/6/f369863aa2814d6e283f859986a1574d.png\" width=\"900\"/></center>\n",
    "\n",
    "Cosine values and their semantic meaning:\n",
    "\n",
    "1 : word vectors mean exactly the same  \n",
    "0 : word vectors are orthogonality (mathematically unrelated)  \n",
    "−1 : word vectors mean exactly opposite  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Words closest to “Sweden”\n",
    "----\n",
    "\n",
    "<center><img src=\"http://deeplearning4j.org/img/sweden_cosine_distance.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/joke.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Word Vector Limitation\n",
    "-------\n",
    "\n",
    "Anatoynms appear to near each other (in both the data and the vector space)!\n",
    "\n",
    "__Examples__:\n",
    "\n",
    "\n",
    "- and / or\n",
    "- good / bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. Arithmetic: Word analogies\n",
    "---\n",
    "\n",
    "The \"Hello, world!\" of word2vec:\n",
    "> Man is to woman as king is to queen\n",
    "\n",
    "$cos(w, king) - cos(w, man) + cos(w, woman) = cos(w, queen)$\n",
    "\n",
    "<center><img src=\"http://multithreaded.stitchfix.com/assets/images/blog/vectors.gif\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Let's play with a demo](http://deeplearner.fz-qqq.net/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Another Demo](http://rare-technologies.com/word2vec-tutorial/#app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Different paths (vectors) through the space encode different relationships.\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plurals\n",
    "-----\n",
    "<center><img src=\"images/plurals.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Verb Tense\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/verb.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Country-Captial\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/country.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How can you use word2vec to build data products?\n",
    "----\n",
    "\n",
    "<center><img src=\"https://assets.toptal.io/uploads/blog/image/827/toptal-blog-image-1423052243609.jpg\" width=\"400\"/></center>\n",
    "\n",
    "When I worked at an employment website, I built a recommendation engine for job seekers. \n",
    "\n",
    "The job seeker would have a resume and we would suggest jobs for them. \n",
    "\n",
    "My goal was given a current job title, suggest a \"better\" job. This would increase platform engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What would be next logical career move from a Babysitter?\n",
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "___Nanny___\n",
    "\n",
    "Nanny is to Babysitter as Senior Engineer is to a Engineer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3) Clustering\n",
    "----\n",
    "\n",
    "<center><img src=\"http://colah.github.io/posts/2015-01-Visualizing-Representations/img/words-pic.png\" width=\"700\"/></center>\n",
    "\n",
    "Use your favorite clustering algo! (K-means is a good start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Example 1](http://colah.github.io/posts/2015-01-Visualizing-Representations/)\n",
    "\n",
    "[Example 2](http://douglasduhaime.com/blog/clustering-semantic-vectors-with-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How can we evaluate word2vec, especially if it is built on a custom corpus?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Word2Vec is an unsupervised learning algorithm. Thus there is no good way to objectively evaluate the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is a testing approach!\n",
    "\n",
    "One possible method is to compare analogies performance with pretrained Google vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "---\n",
    "- After training, any vector operations can be applied to words. \n",
    "- The most common operations are: \n",
    "    - Arithmetic (add and subtract)\n",
    "    - Distance (typically using Cosine Similarity)\n",
    "    - Clustering (typically K-Means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
